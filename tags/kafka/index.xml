<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kafka on </title>
    <link>http://127.0.0.1:1313/hugo/tags/kafka/</link>
    <description>Recent content in kafka on </description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 05 Jan 2022 11:52:23 +0800</lastBuildDate><atom:link href="http://127.0.0.1:1313/hugo/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka</title>
      <link>http://127.0.0.1:1313/hugo/bigdata/kafka/</link>
      <pubDate>Wed, 05 Jan 2022 11:52:23 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/hugo/bigdata/kafka/</guid>
      <description>kafka命令总结 topic的相关操作 创建topic   创建一个叫做“test”的topic，它只有二个分区，一个副本
  bin/kafka-topics.sh &amp;ndash;create &amp;ndash;zookeeper localhost:2181 &amp;ndash;replication-factor 1 &amp;ndash;partitions 2 &amp;ndash;topic test
   名词 解释     &amp;ndash;zookeeper 后面加zookeeper的地址   &amp;ndash;replication-factor 副本数   &amp;ndash;partitions 分区数   &amp;ndash;topic topic的名字      删除topic  bin/kafka-topics.sh &amp;ndash;delete &amp;ndash;zookeeper localhost:2181 &amp;ndash;topic 【topic name】  修改topic  bin/kafka-topics.sh &amp;ndash;zookeeper localhost:2181 &amp;ndash;alter &amp;ndash;partitions 20 &amp;ndash;topic test 修改topic为test的分区为20  查看topic   bin/kafka-topics.</description>
    </item>
    
    <item>
      <title>Kafka</title>
      <link>http://127.0.0.1:1313/hugo/install/kafka/</link>
      <pubDate>Wed, 05 Jan 2022 11:35:47 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/hugo/install/kafka/</guid>
      <description>kafka集群搭建 下载地址  http://kafka.apache.org/downloads.html  开始部署  进入项目前的目录 cd /home/test/ 创建项目目录 mkdir kafka 进入项目目录 cd /home/test/kafka 创建kafka消息目录，主要存放kafka消息 mkdir kafkalogs 进入项目目录 cd /home/test/kafka 上传 kafka_2.10-0.10.0.0.tgz 安装包 解压 tar zxvf kafka_2.10-0.10.0.0.tgz -C ./ cd /home/test/kafka/kafka_2.11-0.10.0.0/config 打开配置文件 vim server.properties  ------------------------配置文件------------------------------------- broker.id=1 /* 这是这台虚拟机上的值，在另外两台虚拟机上应该是2或者3，这个值是唯一的，每台虚拟机或者叫服务器不能相同。 */ listeners=PLAINTEXT://test01:9092 /设置本机IP和端口。我这里设置的是listeners， 也可以直接设置host.name=test01,port=9092, 这个IP地址也是与本机相关的，每台服务器上设置为自己的IP地址。/ log.dirs=/home/test/kafka/kafkalogs #指定其与另外几台一样的ip zookeeper.connect=test01:2181,test01:2181,test02:2181 delete.topic.enable=true num.network.threads=3 #这个是borker进行网络处理的线程数 num.io.threads=8 #这个是borker进行I/O处理的线程数 socket.send.buffer.bytes=102400 #发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能 socket.receive.buffer.bytes=102400 #kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘 socket.request.max.bytes=104857600 #这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小 num.partitions=1 #默认的分区数，一个topic默认1个分区数 log.retention.hours=168 #默认消息的最大持久化时间，168小时，7天 message.max.byte=5242880 #消息保存的最大值5M default.replication.factor=2 #kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务 replica.fetch.max.bytes=5242880 #取消息的最大直接数 log.</description>
    </item>
    
  </channel>
</rss>
