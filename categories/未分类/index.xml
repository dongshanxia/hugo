<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>未分类 on My New Hugo Site</title>
    <link>http://127.0.0.1:1313/hugo/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/</link>
    <description>Recent content in 未分类 on My New Hugo Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 12 Jan 2022 10:38:25 +0800</lastBuildDate><atom:link href="http://127.0.0.1:1313/hugo/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Dongshanxia</title>
      <link>http://127.0.0.1:1313/hugo/about/dongshanxia/</link>
      <pubDate>Wed, 12 Jan 2022 10:38:25 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/hugo/about/dongshanxia/</guid>
      <description>个人介绍  出生: 1995.04 住址: 杭州市滨江区 电话: 13395753926 邮箱: 984801940@qq.com  教育背景    时间 学校 专业     2014.09-2018.07 洛阳理工学院 计算机科学与技术    掌握技能  严格遵守Java开发规范，有良好的面向对象的业务分析能力，代码书写简洁，力求完美开发。 了解jvm 以及 几种常见的jvm的垃圾回收机制 熟练运用Spring和ioc的加载过程 熟练掌握MySql，了解mysql的索引 精通使用kafka，kafka调优，spark,spark调优等大数据技术。 熟练使用SpringMVC，Springboot，Spring Cloud等Spring全家桶系列框架。 熟练使用 PostgreSQL, Redis等数据库和mybatis，mybatisPlus，jdbc等持久层开发技术. 熟练使用fastDFS，Cloudreve等文件存储服务技术。 熟练使用zookeeper , hadoop , hbase , Elasticsearch，Kerboros等技术工具进行开发。 熟练使用maven项目版本，打包和依赖管理工具 熟练使用linux操作系统，网络配置，shell脚本 (grep , sed , awk） 熟练使用docker镜像的分层，docker-compose和docker命令简单使用 熟练使用gitlab和gitlab_ci简单使用 熟悉k8s（正在学习） 熟练使用netty, netty-websock 熟悉Nginx等web服务器。 熟练使用idea，Eclipse开发工具和Git，SVN版本控制工具。 了解go,用go语言写leetcode 会使用异地组网 (蒲公英,zerotier) 博客地址 (见其它补充)  工作经历 杭州合韬科技有限公司  职位: java开发工程师 时间: 2018-03 ~~ 2021-5 职责:  负责公司项目数据接入，分析，入库； Spark , Kafka , Zookeeper集群的维护； Java依赖第三方包的版本进行管理；    浙江火眼金睛数据科技有限公司  职位: 大数据开发工程师 时间: 2021-5 ~~ 2021-8 职责:  负责数据接入和分析   实际事情  安装服务器 维护服务器    项目经历 公安预警系统(西湖指挥中心 六翮凌风)  项目时间:  2018年7月-2020年9月   项目描述:  通过netty,mq,定时任务同步数据库，汇聚到kafka里面，在通过spark 进行规则预警，实时预警推向kafka,数据统计，基础数据入库，redis数据相关性进行分发。(公安具体业务性属于保密信息无法展开)   项目结构  接入层：netty ,ftp,kafka； 分析层：spark； 数据层：MySQL,hbase, PostgreSQL,redis,hadoop。 持久层：MyBatis,jdbc, hbaseUtil； 业务层：Spring 控制层：SpringMVC、Spring SecurityOauth2； 展示层：vue,jsp   负责模块:  前端接入：netty接收tcp和udp的数据，转发ftp数据推向kafka，转发mq数据推向kafka； s三台Kafa集群：kafka topic的基本维护，kafka集群的搭建与基本维护； 15台spark集群：spark程序 分析3W/s左右数据量 预警统计: 对设备的状态及数据量维护。    数据资源中心系统（类似百度网盘的功能)  项目时间:  2020年9月-2021年5月   项目描述:  每个系统都是有一个文件存储和管理的地方，为了解决文件存储 采用了hdfs的文件存储方式，搜索采用了Elasticsearch 进行搜索.</description>
    </item>
    
    <item>
      <title>Picgo</title>
      <link>http://127.0.0.1:1313/hugo/other/picgo/</link>
      <pubDate>Wed, 12 Jan 2022 10:38:25 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/hugo/other/picgo/</guid>
      <description>picgo  地址 : /home/zhu/software/node/node-v14.15.0-linux-x64/bin 文件内容  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  #!/usr/bin/env /home/zhu/software/node/node-v14.15.0-linux-x64/bin/node const path = require(&amp;#39;path&amp;#39;) const minimist = require(&amp;#39;minimist&amp;#39;) const argv = minimist(process.argv.slice(2)) let configPath = argv.c || argv.config || &amp;#39;&amp;#39; if (configPath !== true &amp;amp;&amp;amp; configPath !== &amp;#39;&amp;#39;) { configPath = path.resolve(configPath) } else { configPath = &amp;#39;&amp;#39; } const PicGo = require(&amp;#39;.</description>
    </item>
    
    <item>
      <title>Readme</title>
      <link>http://127.0.0.1:1313/hugo/about/readme/</link>
      <pubDate>Wed, 12 Jan 2022 10:38:25 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/hugo/about/readme/</guid>
      <description>环境准备  需要有hugo的环境  下载项目 hugo地址
创建一个属于某一个的类的文件  hugo new linux/aa.md  最好在项目的根目录执行 linux 相当于文件夹    浏览地址  xcb-github xcb-gitee xcb-netlify-github xcb-vercek-github xcb-home 如果需要自动部署到自己平台 就直接CICD  测试opensearch </description>
    </item>
    
  </channel>
</rss>
